{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download MEaSUREs Annual Antarctic Ice Velocity Maps, Version 1 (NSIDC-0720)\n",
    "\n",
    "\n",
    "NSICD MEaSUREs Annual Antarctic Ice Velocity Maps, Version 1 (NSIDC-0720):\n",
    "\n",
    "https://nsidc.org/data/nsidc-0720/versions/1  <br><br>\n",
    "\n",
    "\n",
    "\n",
    "NASA EarthData Data Access (echo_collection_id=C2245171699-NSIDC_ECS):\n",
    "\n",
    "https://search.earthdata.nasa.gov/search/granules/collection-details?p=C2245171699-NSIDC_ECS&pg[0][v]=f&pg[0][gsk]=-start_date&q=NSIDC-0720%20V001 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import requests\n",
    "import os\n",
    "import IcesheetCHANGES as changes\n",
    "import collection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set options\n",
    "\n",
    "First, set collections key for desired data set from NASA EarthData and set the region name.\n",
    "For the collection ID, set collections_key using the dictionary below, or use the following instructions to add a new collection to the dictionary. \n",
    "\n",
    "Example: Getting a collection ID from EarthData Search: \n",
    "[MEaSUREs Annual Antarctic Ice Velocity Maps V001](https://search.earthdata.nasa.gov/search/granules/collection-details?p=C2245171699-NSIDC_ECS&pg[0][v]=f&pg[0][gsk]=-start_date&q=NSIDC-0720%20V001&tl=1686700071.247!3!!)\n",
    "\n",
    "While viewing the collection on EarthData, as in the above link, follow \"View More Info\" to visit the CMR page for the collection.\n",
    "Then, look for the collections ID in the URL or as a tag below the title. \n",
    "\n",
    "![Locating Collection ID from CMR page](getting_collectionID.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# Data Collection IDs\n",
    "#\n",
    "# MEaSUREs Annual Antarctic Ice Velocity Maps V001\n",
    "# Short Name: MEaSUREs Antarctic Annual Velocity\n",
    "# https://nsidc.org/data/nsidc-0720/versions/1\n",
    "# https://search.earthdata.nasa.gov/search?q=NSIDC-0720%20V001\n",
    "#\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available collections: \n",
      "\n",
      "MEaSUREs Annual Antarctic Ice Velocity Maps V001\n",
      "Short name: MEaSUREs Antarctic Annual Velocity\n",
      "\n",
      "MEaSUREs Greenland Quarterly Ice Sheet Velocity Mosaics from SAR and Landsat V005\n",
      "Short name: MEaSUREs Greenland Quarterly Velocity\n",
      "\n",
      "MEaSUREs Greenland Monthly Ice Sheet Velocity Mosaics from SAR and Landsat, Version 5\n",
      "Short name: MEaSUREs Greenland Monthly Velocity\n",
      "\n",
      "ATLAS/ICESat-2 L3B Gridded Antarctic and Arctic Land Ice Height, Version 2 (ATL14)\n",
      "Short name: ATL14 Antarctic LIH\n",
      "\n",
      "ATLAS/ICESat-2 L3B Gridded Antarctic and Arctic Land Ice Height Change, Version 2 (ATL14)\n",
      "Short name: ATL14 Antarctic LIH Change\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the available collections\n",
    "# You can use either the long or short name as the collection key below\n",
    "collection.print_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection ID:  C2245171699-NSIDC_ECS\n"
     ]
    }
   ],
   "source": [
    "collection_key = 'MEaSUREs Antarctic Annual Velocity'\n",
    "region_name = 'Antarctic'\n",
    "\n",
    "collection_id = collection.collection(collection_key)\n",
    "print('Collection ID: ', collection_id)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, define two directories on your local drive as follows:\n",
    "\n",
    "| directory | purpose | \n",
    "|-----------|---------|\n",
    "|`project_folder` | This is the path where output data from the changes module will be stored - the data to be used directly for analysis. | \n",
    "|`data_folder` | This is the path where ice velocity and elevation data, from their respective sources, will be stored. The data_folder option was created to facilitate data storage on external drives. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_folder = '/Users/tara/Documents/SJSU/MLML/Projects/CHANGES/Examples'\n",
    "data_folder='/Volumes/Seagate/CHANGES/data_repository/tutorial'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the AntarcticCHANGES object - this object will contain all pertinent information to initialize the data grids in your region of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "AC = changes.AntarcticCHANGES(project_folder, data_folder, collection_key, collection_id, region_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data will download to:  /Volumes/Seagate/CHANGES/data_repository/tutorial/Antarctic/Velocity/MEaSUREs Antarctic Annual Velocity/Data\n",
      "Long name:  MEaSUREs Annual Antarctic Ice Velocity Maps V001\n",
      "Short name:  MEaSUREs Antarctic Annual Velocity\n"
     ]
    }
   ],
   "source": [
    "print('Data will download to: ', AC.download_path)\n",
    "print('Long name: ', AC.long_name)\n",
    "print('Short name: ', AC.short_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain list of available files for download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function is from the ICESat2 data page\n",
    "def cmr_filter_urls(search_results):\n",
    "    \"\"\"Select only the desired data files from CMR response.\"\"\"\n",
    "    if 'feed' not in search_results or 'entry' not in search_results['feed']:\n",
    "        return []\n",
    "\n",
    "    \n",
    "    entries = [e['links']\n",
    "                for e in search_results['feed']['entry']\n",
    "                if 'links' in e]\n",
    "    # Flatten \"entries\" to a simple list of links\n",
    "    links = list(itertools.chain(*entries))\n",
    "\n",
    "    urls = []\n",
    "    unique_filenames = set()\n",
    "    for link in links:\n",
    "        if 'href' not in link:\n",
    "            # Exclude links with nothing to download\n",
    "            continue    # continue jumps to next iteration in the loop\n",
    "        if 'inherited' in link and link['inherited'] is True:\n",
    "            # Why are we excluding these links?\n",
    "            continue\n",
    "        if 'rel' in link and 'data#' not in link['rel']:\n",
    "            # Exclude links which are not classified by CMR as \"data\" or \"metadata\"\n",
    "            continue\n",
    "        if 'title' in link and 'opendap' in link['title'].lower():\n",
    "            # Exclude OPeNDAP links--they are responsible for many duplicates\n",
    "            # This is a hack; when the metadata is updated to properly identify\n",
    "            # non-datapool links, we should be able to do this in a non-hack way\n",
    "            continue\n",
    "\n",
    "        filename = link['href'].split('/')[-1]\n",
    "        if filename in unique_filenames:\n",
    "            # Exclude links with duplicate filenames (they would overwrite)\n",
    "            continue\n",
    "        unique_filenames.add(filename)\n",
    "\n",
    "        urls.append(link['href'])\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully obtained 32 URLs.\n"
     ]
    }
   ],
   "source": [
    "# Build and call the CMR API URL\n",
    "cmr_query_url = 'https://cmr.earthdata.nasa.gov/search/granules.json?echo_collection_id=' + AC.collection_id + '&page_size=2000'\n",
    "response = requests.get(cmr_query_url)\n",
    "\n",
    "# print error code based on response\n",
    "if response.status_code != 200:\n",
    "    print('ERROR: {}'.format(response.status_code))\n",
    "search_page = response.json()\n",
    "# If JSON contains an error message, print the message at the key, 'error'\n",
    "if 'errors' in search_page:\n",
    "    print(search_page['errors'])\n",
    "else: \n",
    "    urls = cmr_filter_urls(search_page)\n",
    "    print(\"Successfully obtained {} URLs.\".format(len(urls)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get only .nc files and also store the file names in a seperate list\n",
    "file_links = []\n",
    "file_names = []\n",
    "metadata = []\n",
    "for url in urls:\n",
    "    if '.nc'in url and not 'xml' in url:\n",
    "        file_links.append(url)\n",
    "        url_parts = url.split('/')\n",
    "        file_name = url_parts[-1]\n",
    "        file_names.append(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file written to /Users/tara/Documents/SJSU/MLML/Projects/CHANGES/Examples/Antarctic/Velocity/Metadata/MEaSUREs Antarctic Annual Velocity.csv\n"
     ]
    }
   ],
   "source": [
    "## write available file names and links to csv file\n",
    "metadata_folder = os.path.join(AC.project_folder,AC.region_name,'Velocity','Metadata')\n",
    "if not os.path.exists(metadata_folder):\n",
    "    os.makedirs(metadata_folder)\n",
    "f = open(os.path.join(metadata_folder, AC.short_name + '.csv'),'w')\n",
    "\n",
    "f.write('File_Name,URL')\n",
    "for ea in range(len(file_names)):\n",
    "    f.write('\\n'+file_names[ea]+','+file_links[ea])\n",
    "f.close()\n",
    "\n",
    "print('CSV file written to ' + os.path.join(metadata_folder, AC.short_name + '.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for existing files, get a list of files not on disk\n",
    "def obtain_download_list(file_names, file_links):\n",
    "    \n",
    "    output_folder = AC.download_path\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    download_list_names=[]\n",
    "    download_list_links=[]\n",
    "    for fil in file_names:\n",
    "        download_file = True\n",
    "        if fil not in os.listdir(os.path.join(output_folder)):\n",
    "            for existing_fil in os.listdir(os.path.join(output_folder)):\n",
    "                if fil == existing_fil:  # this allows for older versions to be kept \n",
    "                    download_file = False\n",
    "        else:\n",
    "            download_file=False\n",
    "        if download_file:\n",
    "            download_list_names.append(fil)\n",
    "            download_list_links.append(file_links[file_names.index(fil)])\n",
    "    print('Number of files to download: ' + str(len(download_list_names)))\n",
    "    return(download_list_names, download_list_links) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files to download: 2\n"
     ]
    }
   ],
   "source": [
    "dl_list_names, dl_list_links = obtain_download_list(file_names, file_links)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_nc_direct(file_names, file_links):\n",
    "    not_downloaded_names = []\n",
    "    not_downloaded_links = []\n",
    "\n",
    "    print('Downloading ' + str(len(file_names)) + ' file(s)...')\n",
    "    for i in range(len(file_names)):\n",
    "        # progress report\n",
    "        print('Downloading ' + str(i + 1) + '/' + str(len(file_names)) + ': ' + file_names[i], end='\\r')\n",
    "        # get request (download file)\n",
    "        r = requests.get(file_links[i], allow_redirects=True)\n",
    "        if r.status_code != 200:    # 200 is the standard response for successful HTTP requests\n",
    "            print('ERROR: ' + str(r.status_code) + '\\n')\n",
    "            not_downloaded_names.append(file_names[i])\n",
    "            not_downloaded_links.append(file_links[i])\n",
    "            continue\n",
    "        # write content to file\n",
    "    \n",
    "        open(os.path.join(AC.download_path,file_names[i]), 'wb').write(r.content)\n",
    "    return(not_downloaded_names, not_downloaded_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_download_nc_direct(dl_list_names, dl_list_links):\n",
    "    # Download the files\n",
    "    not_downloaded_names, not_downloaded_links = download_nc_direct(dl_list_names, dl_list_links)\n",
    "\n",
    "    # Attempt to download any files that were not downloaded the first time\n",
    "    if len(not_downloaded_names) > 0:\n",
    "        print('The following files were not downloaded:')\n",
    "        for i in range(len(not_downloaded_names)):\n",
    "            print(not_downloaded_names[i] + ': ' + not_downloaded_links[i])\n",
    "            \n",
    "        print('Attempting to download these files once more...')\n",
    "        not_downloaded_names, not_downloaded_links = download_nc_direct(not_downloaded_names, not_downloaded_links)\n",
    "        if len(not_downloaded_names) > 0:\n",
    "            print('Please download these files manually and place them in the following folder:')\n",
    "            print(AC.download_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 2 file(s)...\n",
      "Downloading 2/2: Antarctica_ice_velocity_2019_2020_1km_v01.1.nc\r"
     ]
    }
   ],
   "source": [
    "run_download_nc_direct(dl_list_names, dl_list_links)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "changes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
