{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download MEaSUREs Greenland Quarterly Ice Sheet Velocity Mosaics from SAR and Landsat V005\n",
    "\n",
    "Short Name/Collection Key: Greenland Quarterly Velocity\n",
    "\n",
    "Collection ID: C2627036252-NSIDC_ECS\n",
    "\n",
    "Sources:\n",
    "\n",
    "https://nsidc.org/data/nsidc-0727/versions/5\n",
    "\n",
    "https://search.earthdata.nasa.gov/search?q=NSIDC-0727%20V005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import requests\n",
    "import os\n",
    "import IcesheetCHANGES as changes\n",
    "import collection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set options\n",
    "\n",
    "First, set collections key for desired data set from NASA EarthData and set the region name.\n",
    "For the collection ID, set collections_key using the dictionary below, or use the following instructions to add a new collection to the dictionary. \n",
    "\n",
    "Example: Getting a collection ID from EarthData Search: \n",
    "[MEaSUREs Annual Antarctic Ice Velocity Maps V001](https://search.earthdata.nasa.gov/search/granules/collection-details?p=C2245171699-NSIDC_ECS&pg[0][v]=f&pg[0][gsk]=-start_date&q=NSIDC-0720%20V001&tl=1686700071.247!3!!)\n",
    "\n",
    "While viewing the collection on EarthData, as in the above link, follow \"View More Info\" to visit the CMR page for the collection.\n",
    "Then, look for the collections ID in the URL or as a tag below the title. \n",
    "\n",
    "![Locating Collection ID from CMR page](getting_collectionID.png)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collection ID Dictionary\n",
    "#### MEaSUREs Greenland Quarterly Ice Sheet Velocity Mosaics from SAR and Landsat V005\n",
    "Short Name/Collection Key: Greenland Quarterly Velocity\n",
    "\n",
    "Collection ID: C2627036252-NSIDC_ECS\n",
    "\n",
    "Sources:\n",
    "\n",
    "https://nsidc.org/data/nsidc-0727/versions/5\n",
    "\n",
    "https://search.earthdata.nasa.gov/search?q=NSIDC-0727%20V005\n",
    " \n",
    "\n",
    "\n",
    "#### MEaSUREs Greenland Monthly Ice Sheet Velocity Mosaics from SAR and Landsat, Version 5\n",
    "Short Name/Collection Key: Greenland Monthly Velocity\n",
    "\n",
    "Collection ID: C2627046644-NSIDC_ECS\n",
    "\n",
    "Sources:\n",
    "\n",
    "https://nsidc.org/data/nsidc-0731/versions/1\n",
    "\n",
    "https://search.earthdata.nasa.gov/search?q=NSIDC-0731%20V005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available collections: \n",
      "\n",
      "MEaSUREs Annual Antarctic Ice Velocity Maps V001\n",
      "Short name: MEaSUREs Antarctic Annual Velocity\n",
      "\n",
      "MEaSUREs Greenland Quarterly Ice Sheet Velocity Mosaics from SAR and Landsat V005\n",
      "Short name: MEaSUREs Greenland Quarterly Velocity\n",
      "\n",
      "MEaSUREs Greenland Monthly Ice Sheet Velocity Mosaics from SAR and Landsat, Version 5\n",
      "Short name: MEaSUREs Greenland Monthly Velocity\n",
      "\n",
      "ATLAS/ICESat-2 L3B Gridded Antarctic and Arctic Land Ice Height, Version 2\n",
      "Short name: ATL14 Antarctic Elevation\n",
      "\n",
      "ATLAS/ICESat-2 L3B Gridded Antarctic and Arctic Land Ice Height Change, Version 2\n",
      "Short name: ATL15 Antarctic Elevation\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print collections in the database (collection.py)\n",
    "collection.print_collections()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SET collection key and region name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_key = 'MEaSUREs Greenland Quarterly Velocity'\n",
    "region_name = 'Greenland'   # 'Greenland' or 'Antarctica'\n",
    "data_type = 'velocity'      # 'velocity' or 'elevation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection ID:  C2627036252-NSIDC_ECS\n"
     ]
    }
   ],
   "source": [
    "collection_id = collection.collection(collection_key)\n",
    "print('Collection ID: ', collection_id)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, define two directories on your local drive as follows:\n",
    "\n",
    "| directory | purpose | \n",
    "|-----------|---------|\n",
    "|`project_folder` | This is the path where output data from the changes module will be stored - the data to be used directly for analysis. | \n",
    "|`data_folder` | This is the path where ice velocity and elevation data, from their respective sources, will be stored. The data_folder option was created to facilitate data storage on external drives. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_folder = '/Users/tara/Documents/SJSU/MLML/Projects/CHANGES/Examples'\n",
    "data_folder='/Volumes/Seagate/CHANGES/data_repository/tutorial'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the AntarcticCHANGES object - this object will contain all pertinent information to initialize the data grids in your region of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "GC = changes.GreenlandCHANGES(project_folder, data_folder, collection_key, collection_id, region_name, data_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region name:\t\t Greenland\n",
      "Collection name:\t MEaSUREs Greenland Quarterly Ice Sheet Velocity Mosaics from SAR and Landsat V005\n",
      "Collection short name:\t MEaSUREs Greenland Quarterly Velocity\n",
      "Collection ID: \t\t C2627036252-NSIDC_ECS\n",
      "Data type:\t\t Velocity\n",
      "Projection:\t\t 3413\n",
      "Download path:\t\t /Volumes/Seagate/CHANGES/data_repository/tutorial/Greenland/Velocity/MEaSUREs Greenland Quarterly Velocity/Data\n",
      "Metadata path:\t\t /Users/tara/Documents/SJSU/MLML/Projects/CHANGES/Examples/Greenland/Velocity/Metadata\n"
     ]
    }
   ],
   "source": [
    "GC.print_attributes()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set verbose output to true or false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain list of available files for download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function is from the ICESat2 data page\n",
    "def cmr_filter_nested_urls(search_results):\n",
    "    \"\"\"Select only the desired data files from CMR response.\"\"\"\n",
    "    if 'feed' not in search_results or 'entry' not in search_results['feed']:\n",
    "        return []\n",
    "\n",
    "    all_urls = []\n",
    "    for e in search_results['feed']['entry']:\n",
    "        granule_id = e['producer_granule_id']\n",
    "        if verbose:\n",
    "            print(granule_id)\n",
    "        urls = []\n",
    "        # TODO can generalize this with an if statement for use with non-nested data, ie. measures_antarctic_annual\n",
    "        urls.append(granule_id)\n",
    "        for link in e['links']:\n",
    "            if 'href' not in link:\n",
    "                # Exclude links with nothing to download\n",
    "                continue    # continue jumps to next iteration in the loop\n",
    "            if 'inherited' in link and link['inherited'] is True:\n",
    "                # Why are we excluding these links?\n",
    "                continue\n",
    "            if 'rel' in link and 'data#' not in link['rel']:\n",
    "                # Exclude links which are not classified by CMR as \"data\" or \"metadata\"\n",
    "                continue\n",
    "            if 'title' in link and 'opendap' in link['title'].lower():\n",
    "                # Exclude OPeNDAP links--they are responsible for many duplicates\n",
    "                # This is a hack; when the metadata is updated to properly identify\n",
    "                # non-datapool links, we should be able to do this in a non-hack way\n",
    "                continue\n",
    "            urls.append(link['href'])\n",
    "        all_urls.append(urls)\n",
    "\n",
    "    return all_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMR request URL:  https://cmr.earthdata.nasa.gov/search/granules.json?echo_collection_id=C2627036252-NSIDC_ECS&page_size=2000\n",
      "Successfully obtained 96 URLs.\n"
     ]
    }
   ],
   "source": [
    "# Build and call the CMR API URL\n",
    "cmr_query_url = 'https://cmr.earthdata.nasa.gov/search/granules.json?echo_collection_id=' + GC.collection_id + '&page_size=2000'\n",
    "response = requests.get(cmr_query_url)\n",
    "\n",
    "print('CMR request URL: ', cmr_query_url)\n",
    "\n",
    "# print error code based on response\n",
    "if response.status_code != 200:\n",
    "    print('ERROR: {}'.format(response.status_code))\n",
    "search_page = response.json()\n",
    "\n",
    "# If JSON contains an error message, print the message at the key, 'error'\n",
    "if 'errors' in search_page:\n",
    "    print(search_page['errors'])\n",
    "else: \n",
    "    #urls = cmr_filter_urls(search_page)\n",
    "    urls = cmr_filter_nested_urls(search_page)\n",
    "    print(\"Successfully obtained {} URLs.\".format(len(urls)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_nested_files(urls):\n",
    "    bad_folders = []\n",
    "    bad_files = 0\n",
    "    downloaded = 0\n",
    "\n",
    "    print(\"Processing \" + str(len(urls)) + \" folders\")\n",
    "    \n",
    "    #for folder in urls:\n",
    "    for i in range(len(urls)):\n",
    "        folder = urls[i]\n",
    "        folder_name = folder[0]\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Processing folder \" + str(i+1) + \"/\" + str(len(urls)) + \": \" + folder_name)\n",
    "         \n",
    "        not_downloaded = []\n",
    "        not_downloaded.append(folder_name)\n",
    "\n",
    "        for link in folder[1:]:\n",
    "            file_name = link.split('/')[-1]\n",
    "                \n",
    "            # if the file exists already, skip it\n",
    "            if os.path.exists(os.path.join(GC.download_path, folder_name, file_name)):\n",
    "                if verbose:\n",
    "                    print('    ' + file_name + ' already exists. Skipping...', end='\\n')\n",
    "                continue\n",
    "            if not file_name.endswith('.tif'):\n",
    "                if verbose:\n",
    "                    print('    ' + file_name + ' is not a tif. Skipping...', end='\\n')\n",
    "                continue\n",
    "            # only download the tif files\n",
    "            if file_name.endswith('.tif'):\n",
    "                if not os.path.exists(os.path.join(GC.download_path, folder_name)):\n",
    "                    os.makedirs(os.path.join(GC.download_path, folder_name))\n",
    "\n",
    "                if verbose:\n",
    "                    print('    Downloading ' + file_name, end='\\n')     \n",
    "\n",
    "                r = requests.get(link, allow_redirects=True)\n",
    "                if r.status_code != 200:    # 200 is the standard response for successful HTTP requests\n",
    "                    print('    ERROR: ' + str(r.status_code) + '\\n')\n",
    "                    print('    Could not download ' + link + '\\n')\n",
    "\n",
    "                    # Add the link to the list of files that were not downloaded\n",
    "                    not_downloaded.append([link])\n",
    "                    bad_files += 1\n",
    "                    continue\n",
    "\n",
    "                # write content to file\n",
    "                open(os.path.join(GC.download_path, folder_name, file_name), 'wb').write(r.content)\n",
    "                downloaded += 1\n",
    "\n",
    "        if (len(not_downloaded)) > 1:\n",
    "            bad_folders.append(not_downloaded)\n",
    "\n",
    "    if (len(bad_folders) > 0):\n",
    "        print('WARNING: ' + str(bad_files) + ' file(s) were not downloaded.')\n",
    "    else:\n",
    "        if verbose:\n",
    "           print(str(downloaded) + ' files downloaded successfully.')\n",
    "\n",
    "    return bad_folders\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_download_nested_files(urls):\n",
    "    # Download the files\n",
    "    not_downloaded = download_nested_files(urls)\n",
    "\n",
    "    # Attempt to download any files that were not downloaded the first time\n",
    "    if len(not_downloaded) > 0:       \n",
    "        print('Attempting to download these files once more...')\n",
    "        not_downloaded = download_nested_files(not_downloaded)\n",
    "        if len(not_downloaded) > 0:\n",
    "            print('WARNING: some files were not downloaded.')\n",
    "            print('Please download the files manually and place in the corresponding folder:')\n",
    "            print('See file: ' + os.path.join(GC.download_path, 'not_downloaded.txt'))\n",
    "            print('\\n')\n",
    "            \n",
    "            # store the list of files that were not downloaded in a text file\n",
    "            with open(os.path.join(GC.download_path, 'not_downloaded.txt'), 'w') as f:\n",
    "                for item in not_downloaded:\n",
    "                    f.write(\"%s\\n\" % item)\n",
    "    if len(not_downloaded) == 0:\n",
    "        print('All files downloaded successfully.')\n",
    "    return not_downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 96 folders\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files downloaded successfully.\n"
     ]
    }
   ],
   "source": [
    "not_downloaded = run_download_nested_files(urls)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
