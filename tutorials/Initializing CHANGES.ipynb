{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using GreenlandCHANGES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goals of this tutorial are:\n",
    "1. describe the steps to initiate the changes module\n",
    "2. highlight several features of the GreenlandCHANGES class to faciliate custom usage\n",
    "3. show an example to run GreenlandCHANGES to compile ArcticDEM elevation data\n",
    "\n",
    "Note that an `init.py` file is additionally provided in the `changes` module which can be edited and run to achieve similar results as those described below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing the GreenlandCHANGES class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To initialize the module from any directory, first add the package to your path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/Users/mhwood/Documents/Research/Scripts/CHANGES/GreenlandCHANGES\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, define two directories on your local drive as follows:\n",
    "\n",
    "| directory | purpose | approximate file size |\n",
    "|-----------|---------|-----------------------|\n",
    "|`project_folder` | This is the path where output data from the changes module will be stored - the data to be used directly for analysis. | The file sizes for this path can be up to a few GB depending on the size and resolution of the sample domain, and the number of sources accessed. |\n",
    "|`data_folder` | This is the path where ice velocity and elevation data, from their respective sources, will be stored. The data_folder option was create facilitate data storage on external drives. | Depending on the data source and whether raw data is kept on disk, this can be several hundreds of GB. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "project_folder = '/Users/mhwood/Documents/Research/Projects/CHANGES/Examples/'\n",
    "data_folder='/Volumes/mhwood/Research/Data Repository/Greenland'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, initialize the GlacierCHANGES object - this object will contain all pertinent information to initialize the data grids in your region of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import changes.initiation.GreenlandCHANGES as gc\n",
    "GC = gc.GreenlandCHANGES(project_folder,data_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "To view the initial attributes in the `GC` class, use the method `print_initiation_parameters`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region Parameters:\n",
      "    region_initiated:  False\n",
      "    region_name:  untitled_region\n",
      "    extents:  []\n",
      " \n",
      "Velocity Parameters:\n",
      "    compile_velocity:  True\n",
      "    velocity_grid_posting:  300\n",
      "    velocity_grid_epsg:  3413\n",
      "    create_velocity_stacks:  True\n",
      "    Velocity Sources:\n",
      "        compile_golive_data: True\n",
      "        compile_tsx_data: True\n",
      " \n",
      "Elevation Parameters:\n",
      "    compile_elevation:  True\n",
      "    elevation_grid_posting:  50\n",
      "    elevation_grid_epsg:  3413\n",
      "    create_elevation_stacks:  True\n",
      "    Elevation Sources:\n",
      "        compile_arcticDEM_data: True\n",
      "        compile_gimp_data: True\n",
      "        compile_glistin_data: True\n",
      "        compile_icesat2_data: True\n",
      "        compile_oib_data: True\n"
     ]
    }
   ],
   "source": [
    "GC.print_initiation_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few things to note for the initial parameters:\n",
    "1. The region has not yet been initiated\n",
    "2. The default parameters for velocity and elevation are all \"True\". In other words, the module, by default, will attempt to download ALL available velocity and elevation.\n",
    "In the next steps, we will adjust these modules to our needs\n",
    "\n",
    "**When all of the parameters have been set correctly, the module will be ready to run using the the `execute_velocity_and_elevation_compilations` method**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the region of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, try to run the execute_velocity_and_elevation_compilations method without specifying the region and its extents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!! Alert !!\n",
      "!! Please define a region name and valid extents before running the compilation !!\n",
      "   There are two options:\n",
      "   Option 1: Pre-defined glacier extent:\n",
      "      GC.set_extents_by_glacier([glacier name here])\n",
      "   Option 2: Custom region and extents:\n",
      "      GC.region_name = [your region here]\n",
      "      GC.extents = [min_x,min_y,max_x,max_y]\n"
     ]
    }
   ],
   "source": [
    "GC.execute_velocity_and_elevation_compilations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we get an alert indicating that the region has not yet been defined - the module does not yet know where to look for available ice velocity and elevation data. Lucky there are two options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Defining the domain with pre-defined glacier extents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the GreenlandCHANGES package, we have provided approximate extents for over 200 Greenland glaciers. These are stored in the `reference` repository.\n",
    "\n",
    "For example, if you were interested in studying Helheim glacier, you can define the region and extents as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GC.set_extents_by_glacier('Helheim')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can check the parameters of the `GC` class to see that the region has now been defined and the extents are present:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region Parameters:\n",
      "    region_initiated:  True\n",
      "    region_name:  Helheim\n",
      "    extents:  [291775.0, -2597975.0, 331975.0, -2557775.0]\n",
      " \n",
      "Velocity Parameters:\n",
      "    compile_velocity:  True\n",
      "    velocity_grid_posting:  300\n",
      "    velocity_grid_epsg:  3413\n",
      "    create_velocity_stacks:  True\n",
      "    Velocity Sources:\n",
      "        compile_golive_data: True\n",
      "        compile_tsx_data: True\n",
      " \n",
      "Elevation Parameters:\n",
      "    compile_elevation:  True\n",
      "    elevation_grid_posting:  50\n",
      "    elevation_grid_epsg:  3413\n",
      "    create_elevation_stacks:  True\n",
      "    Elevation Sources:\n",
      "        compile_arcticDEM_data: True\n",
      "        compile_gimp_data: True\n",
      "        compile_glistin_data: True\n",
      "        compile_icesat2_data: True\n",
      "        compile_oib_data: True\n"
     ]
    }
   ],
   "source": [
    "GC.print_initiation_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Defining a custom region and extents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you wanted to look at a region which did not come pre-defined in this package. In this case, you can manually set the extents of the class by simply accessing and editing the `region_name` and `extents` attributes. \n",
    "\n",
    "For example, if you wanted to look at Petermann glacier, and the pre-defined extents were not suitable for your needs, you could set the region and extents as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GC.region_name = 'Petermann'\n",
    "min_x = -306933\n",
    "min_y = -1019405\n",
    "max_x = -200129\n",
    "max_y = -916708\n",
    "GC.extents = [min_x, min_y, max_x, max_y] #note the order of the extents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the current version of this package only supports coordinates in polar stereographic coordinates.\n",
    "\n",
    "Using the `print_initiation_parameters` method again shows the changes to the class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region Parameters:\n",
      "    region_initiated:  True\n",
      "    region_name:  Petermann\n",
      "    extents:  [-306933, -1019405, -200129, -916708]\n",
      " \n",
      "Velocity Parameters:\n",
      "    compile_velocity:  True\n",
      "    velocity_grid_posting:  300\n",
      "    velocity_grid_epsg:  3413\n",
      "    create_velocity_stacks:  True\n",
      "    Velocity Sources:\n",
      "        compile_golive_data: True\n",
      "        compile_tsx_data: True\n",
      " \n",
      "Elevation Parameters:\n",
      "    compile_elevation:  True\n",
      "    elevation_grid_posting:  50\n",
      "    elevation_grid_epsg:  3413\n",
      "    create_elevation_stacks:  True\n",
      "    Elevation Sources:\n",
      "        compile_arcticDEM_data: True\n",
      "        compile_gimp_data: True\n",
      "        compile_glistin_data: True\n",
      "        compile_icesat2_data: True\n",
      "        compile_oib_data: True\n"
     ]
    }
   ],
   "source": [
    "GC.print_initiation_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An Example: Elevation data from ArcticDEM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, we will demonstrate how to use the `changes` module to obtain [ArcticDEM data from the Polar Geospatial Center](https://www.pgc.umn.edu/data/arcticdem/). Here, we will use Kangerlussuaq glacier as a test example. As describe in the steps above, we will initiate the class and define the region:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GC = gc.GreenlandCHANGES(project_folder,data_folder)\n",
    "GC.region_name = 'Kangerlussuaq'\n",
    "min_x = 474475.0\n",
    "min_y = -2314325.0\n",
    "max_x = 514675.0\n",
    "max_y = -2273975.0\n",
    "GC.extents = [min_x, min_y, max_x, max_y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw in the examples above, all velocity and elevation sources will be run by default. To run the routine for the ArcticDEM data only, we turn off all other sources as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GC.deactivate_all_sources()\n",
    "GC.compile_elevation = True\n",
    "GC.compile_arcticDEM_data = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check that the run parameters are stored as expected by calling the `print_initiation_parameters` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region Parameters:\n",
      "    region_initiated:  True\n",
      "    region_name:  Kangerlussuaq\n",
      "    extents:  [474475.0, -2314325.0, 514675.0, -2273975.0]\n",
      " \n",
      "Velocity Parameters:\n",
      "    compile_velocity:  False\n",
      " \n",
      "Elevation Parameters:\n",
      "    compile_elevation:  True\n",
      "    elevation_grid_posting:  50\n",
      "    elevation_grid_epsg:  3413\n",
      "    create_elevation_stacks:  True\n",
      "    Elevation Sources:\n",
      "        compile_arcticDEM_data: True\n",
      "        compile_gimp_data: False\n",
      "        compile_glistin_data: False\n",
      "        compile_icesat2_data: False\n",
      "        compile_oib_data: False\n"
     ]
    }
   ],
   "source": [
    "GC.print_initiation_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each data source contains additional parameters, which can be viewed with the `print_[source]_parameters` commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ArcticDEM Parameters:\n",
      "    compile_arcticDEM_data:  True\n",
      "    download_new_arcticDEM_data:  True\n",
      "    keep_high_resolution_arcticDEM_data:  False\n",
      "    max_number_of_arcticDEM_files:  all\n"
     ]
    }
   ],
   "source": [
    "GC.print_arcticDEM_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we see a few more details:\n",
    "1. First, the routine will download new arcticDEM data, but the high resolution data will not be saved. Instead, the high resolution data will be downloaded, down-sampled to the posting of the elevation grid, and then the high resolution data will be deleted. This option is the default because the ArcticDEM files are quite large and take up excessive disk space.\n",
    "2. The routine will be run for all available data that overlaps the domain - this option can be changed for testing or for examples.\n",
    "\n",
    "In this example, we will set the maximum number of ArcticDEM files to be 5 - a small subset of the total files for the purposes of illustration in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GC.max_number_of_arcticDEM_files = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now, we are ready to run the module! Note, this will download 5 files for a total of approximately 2 GB (but much of this data will be deleted when the routine is complete). This make take several minutes, depening on your internet and processing speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating elevation compilation for Kangerlussuaq\n",
      "    Running compilation for the ArcticDEM (Worldview) data\n",
      "        Finding a list of ArcticDEM files which overlap the domain\n",
      "            Searching through shapefile provided by PGC to find overlapping files\n",
      "                (This may take a minute or two)\n",
      "            Found 5 files\n",
      "        Downloading files and down-sampling (if not already available)\n",
      "            Checking file SETSM_W1W1_20100417_102001000B398600_102001000DD59500_seg1_2m_v3.0 (n68w034, 1 of 5)\n",
      "              Downloading file...\n",
      "              Downsampling file... \n",
      "                Untaring the data\n",
      "                Working on the down sample\n",
      "                  Reading in the file\n",
      "                  Finding the nearest neighbors\n",
      "            Checking file SETSM_W1W1_20110413_10200100127D6D00_10200100136A9F00_seg1_2m_v3.0 (n68w033, 2 of 5)\n",
      "              Downloading file...\n",
      "              Downsampling file... \n",
      "                Untaring the data\n",
      "                Working on the down sample\n",
      "                  Reading in the file\n",
      "                  Finding the nearest neighbors\n",
      "            Checking file SETSM_W1W1_20110421_1020010012344E00_10200100129B5700_seg1_2m_v3.0 (n68w034, 3 of 5)\n",
      "              Downloading file...\n",
      "              Downsampling file... \n",
      "                Untaring the data\n",
      "                Working on the down sample\n",
      "                  Reading in the file\n",
      "                  Finding the nearest neighbors\n",
      "            Checking file SETSM_W1W1_20110425_10200100129B5700_1020010013B20F00_seg1_2m_v3.0 (n68w034, 4 of 5)\n",
      "              Downloading file...\n",
      "              Downsampling file... \n",
      "                Untaring the data\n",
      "                Working on the down sample\n",
      "                  Reading in the file\n",
      "                  Finding the nearest neighbors\n",
      "            Checking file SETSM_W1W1_20110425_10200100129B5700_1020010014B15000_seg1_2m_v3.0 (n68w034, 5 of 5)\n",
      "              Downloading file...\n",
      "              Downsampling file... \n",
      "                Untaring the data\n",
      "                Working on the down sample\n",
      "                  Reading in the file\n",
      "                  Finding the nearest neighbors\n",
      "        Subsetting the resampled ArcticDEM data onto to the regional domain\n",
      "        Resampling the ArcticDEM data onto to the regional domain\n",
      "          Adding data for date 20100417 (1 of 4)\n",
      "                  Adding data from SETSM_W1W1_20100417_102001000B398600_102001000DD59500_seg1_2m_v3.0 (n68w034)\n",
      "          Adding data for date 20110413 (2 of 4)\n",
      "                  Adding data from SETSM_W1W1_20110413_10200100127D6D00_10200100136A9F00_seg1_2m_v3.0 (n68w033)\n",
      "          Adding data for date 20110421 (3 of 4)\n",
      "                  Adding data from SETSM_W1W1_20110421_1020010012344E00_10200100129B5700_seg1_2m_v3.0 (n68w034)\n",
      "          Adding data for date 20110425 (4 of 4)\n",
      "                  Adding data from SETSM_W1W1_20110425_10200100129B5700_1020010013B20F00_seg1_2m_v3.0 (n68w034)\n",
      "                  Adding data from SETSM_W1W1_20110425_10200100129B5700_1020010014B15000_seg1_2m_v3.0 (n68w034)\n",
      "        Outputting data to /Users/mhwood/Documents/Research/Projects/CHANGES/Examples/Kangerlussuaq/Elevation/Data/Kangerlussuaq ArcticDEM Elevation Grids.nc\n"
     ]
    }
   ],
   "source": [
    "GC.execute_velocity_and_elevation_compilations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Examining the outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the elevation data is compiled, a lot of metadata is printed out to inform you of the progress. When the routine is complete, lets take a look at the outputs:\n",
    "\n",
    "### project_folder\n",
    "\n",
    "First, start with your `project_folder`. We can see that a directory named `Kangerlussuaq` was created in your `project_folder` with a directory as follows:\n",
    "\n",
    "| File | Description |\n",
    "|------|-------------|\n",
    "|Kangerlussuaq CHANGES Process Metadata.txt|A concise output of the metadata printed from the routine|\n",
    "|Elevation\\Metadata\\Kangerlussuaq ArcticDEM Files.csv|A list of all files which overlap the region of interest defined by the extents|\n",
    "|Elevation\\Data\\Kangerlussuaq ArcticDEM Elevation Grids.nc|A netCDF4 file which contains the elevation grids sampled onto the same grid|\n",
    "\n",
    "The final file output is the heart of this package - the homogenized elevation grids.\n",
    "\n",
    "By examing the file in a netCDF4 viewer (such as [Panoply](https://www.giss.nasa.gov/tools/panoply/), recommended), we can see there are 6 output variables - one each for the `x` and `y` dimensions, and 4 each for the data grids. Each data grid is stored by its date (YYYYMMDD) and contains metadata for the files used to generate the grid.\n",
    "\n",
    "But wait! Didn't we specific 5 files? Yes! But two of the files represent elevation measurements on the same day - these were stitched together in one grid. Unfortunately, the first 3 dates in this output (20100417,20100413, and 20100421) do not contain any data on the glacier itself - they just overlap the domain in some way. The final layer (20100425) contains data on the actual glacier terminus. By running this routine for all files available (as listed in Kangerlussuaq ArcticDEM Files.csv), we can identify all available ArcticDEM data for Kangerlussuaq glacier.\n",
    "\n",
    "### data_folder\n",
    "\n",
    "Now, take a look at your `data_folder`. Here you will find a new `Elevation` directory, which contains a new `ArcticDEM` directory, which itself contains 3 new subdirectories as follows:\n",
    "\n",
    "#### 2m_tiles\n",
    "\n",
    "The `2m_tiles` directory will have 2 subdirectories - n68w033 and n68w034. However, these directories are empty! These were used to store the initial data downloaded from PGC, but the files were subsequently deleted after they were processed to save room on the drive. If you would like to keep the raw files, you can set the `keep_high_resolution_arcticDEM_data` method in the `GC` object to `True` prior to running the routine.\n",
    "\n",
    "#### Metadata\n",
    "\n",
    "This directory now contains a shapefile from PGC which outlines the extent of all high resolution ArcticDEM data files available.\n",
    "\n",
    "\n",
    "#### Regridded_50m_tiles\n",
    "\n",
    "In this directory, we have two subdirectories which mirror those in the `2m_tiles` directory: n68w033 and n68w034. These contain the regridded files, sampled at 50m - the posting specified for the output grid. These grids total just over 10 MB in size, compared to the original data size of 2 GB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "changes",
   "language": "python",
   "name": "changes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
